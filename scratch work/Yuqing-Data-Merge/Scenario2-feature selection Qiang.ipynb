{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c82e1b",
   "metadata": {},
   "source": [
    "# Gradient descent algorithm for Scenario 2\n",
    "\n",
    "\n",
    "In this part, we implement an gradient descent algorithm to optimization the objective loss function in Scenario 2:\n",
    "\n",
    "\n",
    "$$\\min F := \\min \\frac{1}{2(n-i)} \\sum_{i=1000}^n (fbpredic(i) + a*tby(i) +b*ffr(i) + c*fta(i) - asp(i))^2$$\n",
    "\n",
    "Gradient descent: \n",
    "\n",
    "$$ \\beta_k = \\beta_{k-1} + \\delta* \\nabla F, $$\n",
    "where $\\delta$ control how far does each iteration go.\n",
    "\n",
    "\n",
    "### Detailed plan\n",
    "\n",
    "First, split the data as train and test with 80% and 20% respectively. For the training part, we need prophet() predicted price, there are a couple of issues. One is prophet() can not predict too far in the future. The other is we can not call prophet() too many times, this takes a lot of time. So we will use a sliding window strategy:\n",
    "\n",
    "1, Split the train data as train_1 and train_2, where train_1 is used as a sliding window to fit prophet(), and give predictions in train_2. Train_2 is used train the model we proposed above.\n",
    "\n",
    "2, After we got full size (size of train_2) predictions from prophet(), then we use gradient descent to fit the above model, extracting the coefficients of features to make predicution in the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed7ef8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec3b16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9bda156",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/yuqingdai/Documents/GitHub/Stock-Erdos/scratch work/Yuqing-Data-Merge/Data/dt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "beb5389e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_csv(path+'/dff1.csv')\n",
    "df = df.rename(columns = {\"Date\":\"ds\",\"Close\":\"y\"}) \n",
    "df = df[['ds', 'y', 'fbsp','diff', 'tby', 'ffr', 'fta', 'eps', 'div', 'per', 'une', 'rus',\n",
    "       'wti', 'ppi', 'rfs', 'vix']]\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c17de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eps_vix'] = df['eps'] * df['vix']\n",
    "df['une_div_tby'] = df['une'] * df['div'] * df['tby']\n",
    "df['une_div_tby_per'] = df['une'] * df['div'] * df['tby'] * df['per']\n",
    "df['wti_div'] = df['wti']  * df['div']\n",
    "df['une_div_tby_per_wti'] = df['une'] * df['div'] * df['tby'] * df['per'] * df['wti']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41461525",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = len(df) - 252\n",
    "df_train = df[:cutoff].copy()\n",
    "df_test = df[cutoff:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3953df8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2300"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9079a597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ds', 'y', 'fbsp', 'diff', 'tby', 'ffr', 'fta', 'eps', 'div', 'per',\n",
       "       'une', 'rus', 'wti', 'ppi', 'rfs', 'vix', 'eps_vix', 'une_div_tby',\n",
       "       'une_div_tby_per', 'wti_div', 'une_div_tby_per_wti'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aabdb28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_features = ['tby', 'ffr', 'fta', 'eps', 'div', 'per',\n",
    "       'une', 'rus', 'wti', 'ppi', 'rfs', 'vix', 'eps_vix', 'une_div_tby',\n",
    "       'une_div_tby_per', 'wti_div','une_div_tby_per_wti']\n",
    "\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    #\"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "\n",
    "#print(list(powerset(possible_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "21b419af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e12dba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tby                      17.140148\n",
      "ffr                     -87.304299\n",
      "fta                      -0.000071\n",
      "eps                      -7.308570\n",
      "div                   -1015.758742\n",
      "per                      16.284204\n",
      "une                     122.954886\n",
      "rus                       0.460901\n",
      "wti                     -19.995957\n",
      "ppi                      -0.568228\n",
      "rfs                       0.004706\n",
      "vix                      -9.431266\n",
      "eps_vix                  -0.009859\n",
      "une_div_tby              -0.307977\n",
      "une_div_tby_per          -0.743147\n",
      "wti_div                   9.507056\n",
      "une_div_tby_per_wti       0.005493\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "reg_new = OLS((df_train['diff']).copy(),df_train[possible_features].copy()).fit()\n",
    "print(reg_new.params)\n",
    "\n",
    "#from the output, we can see it's consistent with sklearn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "45cdc5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131071"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coef = reg_new.params\n",
    "new_possible_feats = new_coef[abs(new_coef)>0].index\n",
    "\n",
    "power_feats = list(powerset(new_possible_feats))\n",
    "power_feats.remove(())\n",
    "\n",
    "power_feats = [ list(feats) for feats in power_feats]\n",
    "len(power_feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_scores = []\n",
    "parameters = []\n",
    "\n",
    "for feats in power_feats:\n",
    "    tmp_reg = OLS((df_train['diff']).copy(),df_train[feats].copy()).fit()\n",
    "    AIC_scores.append(tmp_reg.aic)\n",
    "    parameters.append(tmp_reg.params)\n",
    "\n",
    "    \n",
    "Min_AIC_index = AIC_scores.index(min(AIC_scores))\n",
    "Min_AIC_feats = power_feats[Min_AIC_index]  \n",
    "Min_AIC_params  = parameters[Min_AIC_index]\n",
    "print(Min_AIC_feats)\n",
    "print(Min_AIC_params)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e390d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Min_AIC_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ada352",
   "metadata": {},
   "outputs": [],
   "source": [
    "###After selecting the best features, we report the testing error, and make the plot \n",
    "AIC_df_test = df_test[Min_AIC_feats]\n",
    "AIC_pred_test = AIC_df_test.dot(Min_AIC_params)+df_test.fbsp\n",
    "\n",
    "AIC_df_train = df_train[Min_AIC_feats]\n",
    "AIC_pred_train = AIC_df_train.dot(Min_AIC_params)+ df_train.fbsp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98dd3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "mse_train = MSE(df_train.y, AIC_pred_train) \n",
    "mse_test = MSE(df_test.y, AIC_pred_test)\n",
    "\n",
    "\n",
    "#compare with fbprophet()\n",
    "\n",
    "fb_mse_train = MSE(df_train.y, df_train.fbsp) \n",
    "fb_mse_test = MSE(df_test.y, df_test.fbsp)\n",
    "\n",
    "\n",
    "print(mse_train,fb_mse_train)\n",
    "\n",
    "print(mse_test,fb_mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c73b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,6))\n",
    "plt.plot(df_test.y,label=\"true price\")\n",
    "plt.plot(df_test.fbsp,label=\"fbprophet prediction\")\n",
    "plt.plot(AIC_pred_test,label=\"Prediction by Best_AIC\")\n",
    "plt.legend(fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452552b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
